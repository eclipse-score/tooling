---
id: Tooling-DR-001
status: "Draft (participation requested)"
owner: Infrastructure Community
---

# Decision Record: Integration Strategy for External Development Tools

## Current Open Points

* define tool classes? e.g. fast and slow
* define use cases? e.g. safety vs fast
* describe 2-5 hybrid scenarios, e.g. devcontainer + bazel aspects, bazel multitool + bazel aspects, bazel config to fallback to host tools etc.
* ...


## 1. Context / Problem
Multiple categories of external tooling (formatters, linters, license / SBOM scanners,
static analyzers, code generators, security scanners) are needed across SCORE
repositories. Today we mainly use Bazel multitool; Bazel aspects are emerging; some advocate for devcontainers. None individually optimize for all CI + local needs.

We need a standard approach that scales to additional tools and runs identically in:
CI, local CLI, and IDE/editor integrations.

## 2. Requirements
1. Version Pinning: Identical versions across CLI / CI / IDE; no hidden network fetches during execution (all artifacts hash-pinned).
2. Config Consistency: Central baseline config; local overrides allowed but must be explicit & reviewable (goal: detect drift automatically).
    * Just how many local overrides do we want to allow? Everything? Nothing?
3. Performance: Fast full run & incremental run.
    * Do we need (remote) caching and remote execution? At least caching for a few tools will definitely be required (e.g. clang-tidy).
4. Offline & Retention: Prefetch & store artifacts ≥10 years; fully offline execution path (no network except initial mirror sync).
5. Platforms: Linux x86_64 & aarch64.
6. Low Friction Integration: Minimal per-repo boilerplate; single invocation pattern; easy upgrades.
7. Maintenance Effort: The solution should be as simple as possible.

## 3. Options Considered

### 3.1 Bazel Multitool
Centrally pinned binaries executed via `bazel run`. Current solution.

Pros:
* Simple
* Typically compatible to IDE use cases

Cons:
* does not include sharing centralized config
* does not include caching for executing slow tools
* not all tools can be provided this way (e.g. dot). --> Rare use case? Most tools are packagable.
* requires pre-execution setup (e.g. environment, dependencies)

### 3.2 Bazel Aspects
Graph-aware aspects performing analysis / formatting per target. Newly available solution (incubation).

Pros:
* runs only on affected targets (others are cached)
  * no manual file selection, runs on targets
  * remote execution possible
* linters run on correct/desired configuration as selected via bazel

Cons:
* Development/maintenenance complexity (limited know-how)
* slow execution in some cases
  * e.g. per-target virtual environments required for python - potentially this is so fast, that it's not relevant!
  * e.g. same file in multiple targets will be analyzed twice. But potentially with different configurations.
* no proper IDE integration -> TODO: how to share config? tool versions? IDE extensions? --> currently via ide_support --> devcontainer?
* not all tools can be provided this way (e.g. dot). --> Rare use case? Most tools are packagable.
* not all tools can be provided this way, e.g. plantuml is not an aspect?! --> other solution for such use cases

### 3.3 Devcontainer
Canonical container image as the authoritative tool distribution. Another current solution.

Pros:
* straightforward onboarding (well known concept)
* IDE support out of the box

Cons:
* Large images slow on GitHub CI (can we cache them??) -> TODO: compare to bazel download times!
* Tools might implicitly use content from the container, which is not an explicit dependency. --> is that an issue?

### 3.4 Native Host Installs
Rely on developer & CI host environment package managers.

Pros:
* Fastest invocation, no wrapper overhead.

Cons:
* No version pinning, unenforceable consistency, high drift
* Requires user effort

### 3.5 Hybrid Solution
None of the above need to be truly exclusive.

Pros: Use the simplest viable primitive per tool class; preserve uniform interface for most tools; enable deeper graph-aware optimization only where measurable benefit (e.g., Python dependency analysis, multi-version lint). Devcontainer becomes a generated convenience layer referencing canonical Bazel definitions.
Cons: Two mental models (simple run vs aspect run) to document; requires generation tooling to prevent duplication; still need retention/mirroring design.

TODO: define tool classes? use cases? safety vs fast?

## 4. Evaluation Matrix
Legend: ✅ meets / strong; 🤔 mixed / conditional; ❌ weak; ❓ unknown (needs spike)

| Option             | 1 (Pin) | 2 (Config) | 3 (Perf) | 4 (Offline) | 5 (Plat) | 6 (Sec) | 7 (Friction) | 8 (Maint) |
| ------------------ | ------- | --------- | -------- | ----------- | -------- | ------- | ------------ | --------- |
| Bazel Aspects      | ✅ | ✅ | 🤔 (cache dep) | ❓ | ❓ | ✅ | 🤔 | 🤔 (authoring cost) |
| Bazel Multitool    | ✅ | 🤔 (global cfg) | 🤔 | ❓ | ✅ | ✅ | ✅ | ✅ |
| Devcontainer Only  | ✅ | ✅ | 🤔 (image pull) | ✅ | ✅ | 🤔 (base chain) | ✅ | ✅ |
| Native Host        | ❌ | 🤔 | ✅ | ❌ | 🤔 | ❌ | ❌ | ❌ |
| Hybrid Layer (3.5) | ✅ | ✅ (override path) | ✅ (choose best mech) | 🤔 (need mirror) | ✅ | ✅ | ✅ | ✅ |

Notes:
* (3) Performance: Hybrid allows aspects only where they materially reduce runtime (e.g., incremental on changed targets) while keeping trivial tools fast via direct invocation.
* (4) Offline: Mirror strategy (artifact store / OCI + metadata lock) still to be implemented for any option; container-only slightly ahead due to image snapshot capability.
* (2) Config: Hybrid defines layering: baseline central config -> optional repo override -> (future) per-target aspect refinement if justified.
